{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bkosa2/anaconda3/envs/rnp/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import functorch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import random\n",
    "import idx2numpy  # conda install pip, then pip install idx2numpy - allows us to easily convert un gziped mnist files to numpy arrays\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bkosa2/RNP/RNP_PyTorch/Pytorch_hypernets/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Important for using GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "# input_size = 784  # 28x28\n",
    "# synthnet_hidden_size = 100\n",
    "# num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably a little extra, but here's a function that is purely meant to \n",
    "# download the MNIST dataset. If the data/mnist_data/MNIST/raw/... MNIST data\n",
    "# files already exist, then just return the mnist data\n",
    "# in a list format ==> [[train_images], [train_labels], [test_images], [test_labels]] \n",
    "# def download_mnist(url,file_dict=None):\n",
    "#     if file_dict is not None:\n",
    "#         mnist_data=list()\n",
    "#         try:\n",
    "#             for i, key in enumerate(file_dict.keys()):    \n",
    "#                 fname = file_dict[key]\n",
    "#                 url = os.path.join(url,fname)\n",
    "#                 isExist = os.path.exists(fname)\n",
    "#                 if not isExist:\n",
    "#                     response = requests.get(url, stream=True)\n",
    "#                     fsize=len(response.content)\n",
    "#                     print(url)\n",
    "#                     with open(fname, 'wb') as fout:\n",
    "#                         for data in tqdm(response.iter_content(), desc =fname, total=fsize):\n",
    "#                             fout.write(data)\n",
    "                \n",
    "#                 with gzip.open(fname, \"rb\") as f_in:                \n",
    "#                     if fname.find('idx3') != -1:        \n",
    "#                         mnist_data.append(np.frombuffer(f_in.read(), np.uint8, offset=16).reshape(-1, 28, 28)) #if images        \n",
    "#                     else:                               \n",
    "#                         mnist_data.append(np.frombuffer(f_in.read(), np.uint8, offset=8))  #if labels\n",
    "#             #return mnist_data in a list format ==> [[train_images], [train_labels], [test_images], [test_labels]] \n",
    "#             return mnist_data\n",
    "#         except Exception as e:\n",
    "#             print(\"Something went wrong:\", e)\n",
    "#     else:\n",
    "#         print(\"file_dict cannot be None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the normal MNIST dataset into train and testing dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../data/mnist_data', \n",
    "                                                          download=True, \n",
    "                                                          train=True,\n",
    "                                                          transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                                          ])), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# download and transform test dataset\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST('../data/mnist_data', \n",
    "                                                          download=True, \n",
    "                                                          train=False,\n",
    "                                                          transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                                          ])), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqMNISTDataset(Dataset):\n",
    "    \"\"\" Custom Sequential MNIST dataset \"\"\"\n",
    "    def __init__(self, digit_seqs, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            digit_seqs (list): a list of\n",
    "            labels (list): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.digit_seqs = digit_seqs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        digit_seq = self.digit_seqs[idx]\n",
    "        digit_seq = self.transform(np.array(digit_seq))\n",
    "        return digit_seq, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mnist dataset as numpy arrays.\n",
    "train_images_path = os.path.normpath(\"../data/mnist_data/MNIST/raw/train-images-idx3-ubyte\")\n",
    "train_labels_path = os.path.normpath(\"../data/mnist_data/MNIST/raw/train-labels-idx1-ubyte\")\n",
    "test_images_path = os.path.normpath(\"../data/mnist_data/MNIST/raw/t10k-images-idx3-ubyte\")\n",
    "test_labels_path = os.path.normpath(\"../data/mnist_data/MNIST/raw/t10k-labels-idx1-ubyte\")\n",
    "train_images = idx2numpy.convert_from_file(train_images_path)\n",
    "train_labels = idx2numpy.convert_from_file(train_labels_path)\n",
    "test_images = idx2numpy.convert_from_file(test_images_path)\n",
    "test_labels = idx2numpy.convert_from_file(test_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "(5923, 28, 28)\n",
      "(6742, 28, 28)\n",
      "(5958, 28, 28)\n",
      "(6131, 28, 28)\n",
      "(5842, 28, 28)\n",
      "(5421, 28, 28)\n",
      "(5918, 28, 28)\n",
      "(6265, 28, 28)\n",
      "(5851, 28, 28)\n",
      "(5949, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Create our custom mnist sequential dataset where each input\n",
    "# is 5 MNIST digits in order and the corresponding label is the next digit.\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "train_zeros = train_images[train_labels == 0, :, :]\n",
    "train_ones = train_images[train_labels == 1, :, :]\n",
    "train_twos = train_images[train_labels == 2, :, :]\n",
    "train_threes = train_images[train_labels == 3, :, :]\n",
    "train_fours = train_images[train_labels == 4, :, :]\n",
    "train_fives = train_images[train_labels == 5, :, :]\n",
    "train_sixes = train_images[train_labels == 6, :, :]\n",
    "train_sevens = train_images[train_labels == 7, :, :]\n",
    "train_eights = train_images[train_labels == 8, :, :]\n",
    "train_nines = train_images[train_labels == 9, :, :]\n",
    "train_ordered = [train_zeros,\n",
    "                 train_ones, \n",
    "                 train_twos, \n",
    "                 train_threes, \n",
    "                 train_fours, \n",
    "                 train_fives, \n",
    "                 train_sixes, \n",
    "                 train_sevens, \n",
    "                 train_eights, \n",
    "                 train_nines]\n",
    "\n",
    "print(train_zeros.shape)\n",
    "print(train_ones.shape)\n",
    "print(train_twos.shape)\n",
    "print(train_threes.shape)\n",
    "print(train_fours.shape)\n",
    "print(train_fives.shape)\n",
    "print(train_sixes.shape)\n",
    "print(train_sevens.shape)\n",
    "print(train_eights.shape)\n",
    "print(train_nines.shape)\n",
    "\n",
    "smallest_train_set_size = min(train_zeros.shape[0], \\\n",
    "                        train_ones.shape[0], \\\n",
    "                        train_twos.shape[0], \\\n",
    "                        train_threes.shape[0], \\\n",
    "                        train_fours.shape[0], \\\n",
    "                        train_fives.shape[0], \\\n",
    "                        train_sixes.shape[0], \\\n",
    "                        train_sevens.shape[0], \\\n",
    "                        train_eights.shape[0], \\\n",
    "                        train_nines.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(980, 28, 28)\n",
      "(1135, 28, 28)\n",
      "(1032, 28, 28)\n",
      "(1010, 28, 28)\n",
      "(982, 28, 28)\n",
      "(892, 28, 28)\n",
      "(958, 28, 28)\n",
      "(1028, 28, 28)\n",
      "(974, 28, 28)\n",
      "(1009, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Create our custom mnist sequential dataset where each input\n",
    "# is 5 MNIST digits in order and the corresponding label is the next digit.\n",
    "test_zeros = test_images[test_labels == 0, :, :]\n",
    "test_ones = test_images[test_labels == 1, :, :]\n",
    "test_twos = test_images[test_labels == 2, :, :]\n",
    "test_threes = test_images[test_labels == 3, :, :]\n",
    "test_fours = test_images[test_labels == 4, :, :]\n",
    "test_fives = test_images[test_labels == 5, :, :]\n",
    "test_sixes = test_images[test_labels == 6, :, :]\n",
    "test_sevens = test_images[test_labels == 7, :, :]\n",
    "test_eights = test_images[test_labels == 8, :, :]\n",
    "test_nines = test_images[test_labels == 9, :, :]\n",
    "test_ordered = [test_zeros,\n",
    "                 test_ones, \n",
    "                 test_twos, \n",
    "                 test_threes, \n",
    "                 test_fours, \n",
    "                 test_fives, \n",
    "                 test_sixes, \n",
    "                 test_sevens, \n",
    "                 test_eights, \n",
    "                 test_nines]\n",
    "\n",
    "print(test_zeros.shape)\n",
    "print(test_ones.shape)\n",
    "print(test_twos.shape)\n",
    "print(test_threes.shape)\n",
    "print(test_fours.shape)\n",
    "print(test_fives.shape)\n",
    "print(test_sixes.shape)\n",
    "print(test_sevens.shape)\n",
    "print(test_eights.shape)\n",
    "print(test_nines.shape)\n",
    "\n",
    "smallest_test_set_size = min(test_zeros.shape[0], \\\n",
    "                        test_ones.shape[0], \\\n",
    "                        test_twos.shape[0], \\\n",
    "                        test_threes.shape[0], \\\n",
    "                        test_fours.shape[0], \\\n",
    "                        test_fives.shape[0], \\\n",
    "                        test_sixes.shape[0], \\\n",
    "                        test_sevens.shape[0], \\\n",
    "                        test_eights.shape[0], \\\n",
    "                        test_nines.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.  51. 159. 253. 159.  50.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n  48. 238. 252. 252. 252. 237.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n 227. 253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  60. 224.\n 252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252.\n 252. 253. 252. 252.  96. 189. 253. 167.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253.\n 190. 114. 253. 228.  47.  79. 255. 168.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 179.\n  12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.  38. 165. 253. 233. 208.  84.\n   0.   0.   0.   0.   0.   0. 253. 252. 165.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   7. 178. 252. 240.  71.  19.  28.\n   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.  57. 252. 252.  63.   0.   0.   0.\n   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0. 198. 253. 190.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0. 255. 253. 196.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  76. 246. 252. 112.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0. 253. 252. 148.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 230.  25.   0.   0.   0.   0.\n   0.   0.   0.   0.   7. 135. 253. 186.  12.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 223.   0.   0.   0.   0.   0.\n   0.   0.   0.   7. 131. 252. 225.  71.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 145.   0.   0.   0.   0.   0.\n   0.   0.  48. 165. 252. 173.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  86. 253. 225.   0.   0.   0.   0.   0.\n   0. 114. 238. 253. 162.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178.\n 225. 253. 223. 167.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229. 215. 252. 252.\n 252. 196. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  28. 199. 252. 252. 253. 252. 252. 233.\n 145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.  25. 128. 252. 253. 252. 141.  37.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m first_digit \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m5\u001b[39m)\n\u001b[1;32m      8\u001b[0m train_seq \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 9\u001b[0m train_seq\u001b[39m.\u001b[39mappend(normalize(train_ordered[first_digit][i]\u001b[39m.\u001b[39;49mflatten())\u001b[39m.\u001b[39mreshape((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     10\u001b[0m train_seq\u001b[39m.\u001b[39mappend(normalize(train_ordered[first_digit \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m][i]\u001b[39m.\u001b[39mflatten())\u001b[39m.\u001b[39mreshape((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     11\u001b[0m train_seq\u001b[39m.\u001b[39mappend(normalize(train_ordered[first_digit \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m][i]\u001b[39m.\u001b[39mflatten())\u001b[39m.\u001b[39mreshape((\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:1817\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1815\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a supported axis\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m axis)\n\u001b[0;32m-> 1817\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1818\u001b[0m     X,\n\u001b[1;32m   1819\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49msparse_format,\n\u001b[1;32m   1820\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1821\u001b[0m     estimator\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthe normalize function\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1822\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m   1823\u001b[0m )\n\u001b[1;32m   1824\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1825\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/sklearn/utils/validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    907\u001b[0m         )\n\u001b[1;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    913\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.  51. 159. 253. 159.  50.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n  48. 238. 252. 252. 252. 237.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  54.\n 227. 253. 252. 239. 233. 252.  57.   6.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  10.  60. 224.\n 252. 253. 252. 202.  84. 252. 253. 122.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 163. 252. 252.\n 252. 253. 252. 252.  96. 189. 253. 167.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  51. 238. 253. 253.\n 190. 114. 253. 228.  47.  79. 255. 168.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.  48. 238. 252. 252. 179.\n  12.  75. 121.  21.   0.   0. 253. 243.  50.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.  38. 165. 253. 233. 208.  84.\n   0.   0.   0.   0.   0.   0. 253. 252. 165.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   7. 178. 252. 240.  71.  19.  28.\n   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.  57. 252. 252.  63.   0.   0.   0.\n   0.   0.   0.   0.   0.   0. 253. 252. 195.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0. 198. 253. 190.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0. 255. 253. 196.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  76. 246. 252. 112.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0. 253. 252. 148.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 230.  25.   0.   0.   0.   0.\n   0.   0.   0.   0.   7. 135. 253. 186.  12.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 223.   0.   0.   0.   0.   0.\n   0.   0.   0.   7. 131. 252. 225.  71.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 145.   0.   0.   0.   0.   0.\n   0.   0.  48. 165. 252. 173.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  86. 253. 225.   0.   0.   0.   0.   0.\n   0. 114. 238. 253. 162.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 249. 146.  48.  29.  85. 178.\n 225. 253. 223. 167.  56.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  85. 252. 252. 252. 229. 215. 252. 252.\n 252. 196. 130.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.  28. 199. 252. 252. 253. 252. 252. 233.\n 145.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.  25. 128. 252. 253. 252. 141.  37.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Create the training digit sequence samples\n",
    "train_seqs = []\n",
    "train_labels = []\n",
    "# If this isn't enough data, then I can increase the size.\n",
    "for i in range(smallest_train_set_size):\n",
    "    # Each image's px values are [0, 255]. Normalize to [0, 1]\n",
    "    first_digit = random.randint(0, 5)\n",
    "    train_seq = []\n",
    "    train_seq.append(normalize(train_ordered[first_digit][i].flatten()).reshape((28, 28), dim=0))\n",
    "    train_seq.append(normalize(train_ordered[first_digit + 1][i].flatten()).reshape((28, 28), dim=0))\n",
    "    train_seq.append(normalize(train_ordered[first_digit + 2][i].flatten()).reshape((28, 28), dim=0))\n",
    "    train_seq.append(normalize(train_ordered[first_digit + 3][i].flatten()).reshape((28, 28), dim=0))\n",
    "    train_seq.append(normalize(train_ordered[first_digit + 4][i].flatten()).reshape((28, 28), dim=0))\n",
    "    train_seqs.append(train_seq)\n",
    "    train_labels.append(first_digit + 5)\n",
    "\n",
    "# plt.imshow(train_zeros[5000].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the testing digit sequence samples\n",
    "test_seqs = []\n",
    "test_labels = []\n",
    "for i in range(smallest_test_set_size):\n",
    "    first_digit = random.randint(0, 5)\n",
    "    test_seq = []\n",
    "    test_seq.append(test_ordered[first_digit][i])\n",
    "    test_seq.append(test_ordered[first_digit + 1][i])\n",
    "    test_seq.append(test_ordered[first_digit + 2][i])\n",
    "    test_seq.append(test_ordered[first_digit + 3][i])\n",
    "    test_seq.append(test_ordered[first_digit + 4][i])\n",
    "    test_seqs.append(test_seq)\n",
    "    test_labels.append(first_digit + 5)\n",
    "\n",
    "# plt.imshow(train_zeros[5000].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor and normalize\n",
    "train_seqs = nn.functional.normalize(torch.FloatTensor(np.array(train_seqs)))\n",
    "train_labels = nn.functional.normalize(torch.FloatTensor(np.array(train_labels)))\n",
    "test_seqs = nn.functional.normalize(torch.FloatTensor(np.array(test_seqs)))\n",
    "test_labels = nn.functional.normalize(torch.FloatTensor(np.array(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 5, 5421)\n"
     ]
    }
   ],
   "source": [
    "# Normalize each individual image along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me just making sure it looks right\n",
    "print(f\"len of train_seqs = {len(train_seqs)}\")\n",
    "print(f\"len of first element in train_seqs = {len(train_seqs[0])}\")\n",
    "print(f\"len of train_labels = {len(train_labels)}\")\n",
    "\n",
    "print(f\"len of test_seqs = {len(test_seqs)}\")\n",
    "print(f\"len of first element in test_seqs = {len(test_seqs[0])}\")\n",
    "print(f\"len of test_labels = {len(test_labels)}\")\n",
    "\n",
    "i = 2000\n",
    "plt.imshow(train_seqs[i][0].reshape(28, 28), cmap='gray')\n",
    "plt.imshow(train_seqs[i][1].reshape(28, 28), cmap='gray')\n",
    "plt.imshow(train_seqs[i][2].reshape(28, 28), cmap='gray')\n",
    "plt.imshow(train_seqs[i][3].reshape(28, 28), cmap='gray')\n",
    "plt.imshow(train_seqs[i][4].reshape(28, 28), cmap='gray')\n",
    "print(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data into a DataSet and DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(SeqMNISTDataset(train_seqs, train_labels), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# download and transform test dataset\n",
    "test_loader = torch.utils.data.DataLoader(SeqMNISTDataset(test_seqs, test_labels), \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperNetwork(torch.nn.Module):\n",
    "    def __init__(self, hypnet: torch.nn.Module, synthnet: torch.nn.Module):\n",
    "        # hypnet is the network that takes an embedding z and produces the parameters of synthnet\n",
    "        # synthnet is the network that takes input x and produces h\n",
    "        super().__init__()\n",
    "        s_func, s_params0 = functorch.make_functional(synthnet)\n",
    "\n",
    "        # store the information about the parameters\n",
    "        self._sp_shapes = [sp.shape for sp in s_params0]\n",
    "\n",
    "        # These are the index offsets for each parameter (e.g. set of weights between\n",
    "        # each layer and set of biases for each layer)\n",
    "        self._sp_offsets = np.array([0, *np.cumsum([sp.numel() for sp in s_params0])])\n",
    "\n",
    "        # make the synthnet_func to accept batched parameters\n",
    "        synthnet_func = functorch.vmap(s_func)\n",
    "        # a workaround of functorch's bug #793\n",
    "        # self._synthnet_batched_func = [synthnet_func]\n",
    "        self._synthnet_batched_func = synthnet_func\n",
    "        self._hypnet = hypnet\n",
    "\n",
    "    def forward(self, x: torch.Tensor, z: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch_size, nx), z: (batch_size, nz)\n",
    "        params = self._hypnet(z)  # params: (batch_size, nparams_tot)\n",
    "\n",
    "        # rearrange params to have the same shape as the synthnet params, except on the batch dimension\n",
    "        # print(f\"self._sp_offsets: {self._sp_offsets}\")\n",
    "        params_lst = []\n",
    "        for i, shape in enumerate(self._sp_shapes):\n",
    "            j0, j1 = self._sp_offsets[i], self._sp_offsets[i + 1]\n",
    "            params_lst.append(params[..., j0:j1].reshape(-1, *shape))\n",
    "\n",
    "        # print(f\"params_lst: {params_lst}\")\n",
    "\n",
    "        # apply the function to the batched parameters and x\n",
    "        h = self._synthnet_batched_func(params_lst, x)\n",
    "        return h\n",
    "        # return params_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Building an linear encoder with Linear\n",
    "        # layer followed by Relu activation function\n",
    "        # 784 ==> 9\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(64, 36),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(36, 18),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(18, 9)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class RNN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(RNN, self).__init__()\n",
    "\n",
    "#         self.hidden_size = hidden_size\n",
    "\n",
    "#         self.i2h = torch.nn.Linear(input_size + hidden_size, hidden_size)\n",
    "#         self.i2o = torch.nn.Linear(input_size + hidden_size, output_size)\n",
    "#         self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "\n",
    "#     def forward(self, input, hidden):\n",
    "#         combined = torch.cat((input, hidden), 1)\n",
    "#         hidden = self.i2h(combined)\n",
    "#         output = self.i2o(combined)\n",
    "#         output = self.softmax(output)\n",
    "#         return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # Number of hidden dims\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Init hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[: ,-1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([0, *np.cumsum([sp.numel() for sp in a])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthnet = torch.nn.Sequential(\n",
    "    torch.nn.Linear(28*28, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, 10),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using an RNN as a synthnet\n",
    "input_dim = 28    # input dimension\n",
    "hidden_dim = 100  # hidden layer dimension\n",
    "layer_dim = 1     # number of hidden layers\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "synthnet_rnn = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthnet params for simple feed forward nn\n",
    "_, synthnet_params = functorch.make_functional(synthnet)\n",
    "n_synthnet_params = sum([p.numel() for p in synthnet_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ben's Code - Just me peeking inside the synthnet_params to understand what PyTorch Module params actually are under the hood. synthnet is just a nn with 1 hidden layer.\n",
    "print(len(synthnet_params))\n",
    "print(synthnet_params[0].size())  # The weights for the connections from input layer (784 units) to hidden layer (100 units)\n",
    "print(synthnet_params[1].size())  # The biases for each of the 100 units in the hidden layer???\n",
    "print(synthnet_params[2].size())  # The weights for the connections from the hidden layer (100 units) to the output layer (10 units)\n",
    "print(synthnet_params[3].size())  # The biases for each of the 10 units in the output layer???\n",
    "print(n_synthnet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params for RNN synthnet\n",
    "_, synthnet_params = functorch.make_functional(synthnet_rnn)\n",
    "n_synthnet_params = sum([p.numel() for p in synthnet_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "14010\n"
     ]
    }
   ],
   "source": [
    "# Ben's Code - Just me peeking inside the synthnet_params to understand what PyTorch Module params actually are under the hood. \n",
    "# synthnet_rnn is just an RNN with 1 hidden layer with 100 units.\n",
    "print(len(synthnet_params))\n",
    "print(synthnet_params[0].size())  # W_ih (28 x 100)\n",
    "print(synthnet_params[1].size())  # W_hh (100 x 100)\n",
    "print(synthnet_params[2].size())  # b_ih[0], where k is the ith layer\n",
    "print(synthnet_params[3].size())  # b_hh[0]\n",
    "print(synthnet_params[4].size())  # W_ho\n",
    "print(synthnet_params[5].size())  # b_o\n",
    "print(n_synthnet_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypnet = torch.nn.Sequential(\n",
    "    torch.nn.Linear(9, 100),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(100, n_synthnet_params),\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = HyperNetwork(hypnet, synthnet_rnn).to(device)\n",
    "encoder = Encoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx should also be 2-D but got 3-D tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m\u001b[39m*\u001b[39m\u001b[39m28\u001b[39m)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m z \u001b[39m=\u001b[39m encoder(inputs)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m module(inputs, z)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m, in \u001b[0;36mHyperNetwork.forward\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     31\u001b[0m     params_lst\u001b[39m.\u001b[39mappend(params[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, j0:j1]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39mshape))\n\u001b[1;32m     33\u001b[0m \u001b[39m# print(f\"params_lst: {params_lst}\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[39m# apply the function to the batched parameters and x\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_synthnet_batched_func(params_lst, x)\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m h\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/functorch/_src/vmap.py:362\u001b[0m, in \u001b[0;36mvmap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m _check_out_dims_is_int_or_int_pytree(out_dims, func)\n\u001b[1;32m    361\u001b[0m batch_size, flat_in_dims, flat_args, args_spec \u001b[39m=\u001b[39m _process_batched_inputs(in_dims, args, func)\n\u001b[0;32m--> 362\u001b[0m \u001b[39mreturn\u001b[39;00m _flat_vmap(\n\u001b[1;32m    363\u001b[0m     func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    364\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/functorch/_src/vmap.py:35\u001b[0m, in \u001b[0;36mdoesnt_support_saved_tensors_hooks.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mdisable_saved_tensors_hooks(message):\n\u001b[0;32m---> 35\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/functorch/_src/vmap.py:489\u001b[0m, in \u001b[0;36m_flat_vmap\u001b[0;34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     batched_inputs \u001b[39m=\u001b[39m _create_batched_inputs(flat_in_dims, flat_args, vmap_level, args_spec)\n\u001b[0;32m--> 489\u001b[0m     batched_outputs \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49mbatched_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    490\u001b[0m     \u001b[39mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n\u001b[1;32m    491\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/functorch/_src/make_functional.py:313\u001b[0m, in \u001b[0;36mFunctionalModule.forward\u001b[0;34m(self, params, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m old_state \u001b[39m=\u001b[39m _swap_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateless_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames_map, params)\n\u001b[1;32m    312\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstateless_model(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    314\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     \u001b[39m# Remove the loaded state on self.stateless_model\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     _swap_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstateless_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames_map, old_state)\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m, in \u001b[0;36mRNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m h0 \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_dim, x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim))\n\u001b[1;32m     21\u001b[0m \u001b[39m# One time step\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m out, hn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrnn(x, h0)\n\u001b[1;32m     23\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc(out[: ,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :])\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/rnp/lib/python3.10/site-packages/torch/nn/modules/rnn.py:450\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m hx \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m         \u001b[39mif\u001b[39;00m hx\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 450\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    451\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor unbatched 2-D input, hx should also be 2-D but got \u001b[39m\u001b[39m{\u001b[39;00mhx\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m-D tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         hx \u001b[39m=\u001b[39m hx\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx should also be 2-D but got 3-D tensor"
     ]
    }
   ],
   "source": [
    "# Just for Ben to run one iteraiton of hypernet forward func to see what's going on\n",
    "# under the hood.\n",
    "inputs, _ = next(iter(train_loader))\n",
    "inputs = inputs.view(-1, 28*28).to(device)\n",
    "z = encoder(inputs).to(device)\n",
    "module(inputs, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for if you want to test out our HyperNet pipeline with a random input embedding z (that is not generated from an encoder)\n",
    "# z = torch.randn(32, 3)\n",
    "# x, y = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([*module.parameters(), *encoder.parameters()], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 105/600 [00:02<00:12, 40.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   101] loss: 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 206/600 [00:05<00:09, 40.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   201] loss: 0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 306/600 [00:07<00:07, 39.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   301] loss: 0.180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 406/600 [00:10<00:04, 40.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   401] loss: 0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 504/600 [00:12<00:02, 42.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   501] loss: 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:14<00:00, 40.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   601] loss: 0.145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 104/600 [00:02<00:12, 40.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   101] loss: 0.106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 206/600 [00:05<00:09, 41.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   201] loss: 0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 308/600 [00:07<00:07, 39.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   301] loss: 0.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 406/600 [00:10<00:04, 40.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   401] loss: 0.095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 505/600 [00:12<00:02, 40.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   501] loss: 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:14<00:00, 40.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   601] loss: 0.095\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset num_epochs times\n",
    "    running_loss = 0.0\n",
    "    i = 0  # Just keeps track of which batch we're on until we get to batch 500, in which case we print\n",
    "           # out the aggregated loss over the 500 batches and reset (i.e. allows us to just print out the\n",
    "           # average loss every 500 batches instead of every batch)\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = inputs.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        z = encoder(inputs).to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # outputs = module(inputs, weights).reshape(-1, 10)\n",
    "        outputs = module(inputs, z).reshape(-1, 10)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        i += 1\n",
    "        if i % 100 == 0:    # print every 500 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the accuracy of our trained model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "def calc_accuracy(test_loader):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            z = encoder(images).to(device)\n",
    "            outputs = module(images, z).reshape(-1, 10)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += labels.size(0)\n",
    "            n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.99"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_accuracy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
